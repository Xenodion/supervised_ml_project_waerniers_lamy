{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "969f3658",
   "metadata": {},
   "source": [
    "# Machine Learning Project\n",
    "by Alexandre Waerniers and Vincent Lamy,\n",
    "\n",
    "students at Albert School x Mines Paris PSL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac80c08f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d499db21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\ALBERTSCHOOL\\SupervisedML\\supervised_ml_project_waerniers_lamy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "\n",
    "from utils import bool_contact, train_ts, modify_pdays\n",
    "\n",
    "# Get project path\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71fc32a",
   "metadata": {},
   "source": [
    "# Download datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c18be99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp.var.rate    41188 non-null  float64\n",
      " 16  cons.price.idx  41188 non-null  float64\n",
      " 17  cons.conf.idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr.employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  int64  \n",
      "dtypes: float64(5), int64(6), object(10)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# raw dataset\n",
    "bank_full = pd.read_csv(os.path.join(cwd, \"data\", \"bank-additional-full.csv\"), sep=\";\")\n",
    "bank_full.y = bank_full.y.map({\"yes\": 1, \"no\":0})\n",
    "\n",
    "bank_full.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b6ba13",
   "metadata": {},
   "source": [
    "# Define metrics, parameters and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c218bca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['precision', 'recall', 'f1', 'accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6637b771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First param grid (basic)\n",
    "# param_grids = {\n",
    "#     'Logistic Regression': {\n",
    "#         'classifier__C': [0.1, 1, 10, 100],\n",
    "#         'classifier__penalty': ['l2'],\n",
    "#         'classifier__solver': ['lbfgs', 'liblinear']\n",
    "#     },\n",
    "\n",
    "#     'Random Forest': {\n",
    "#         'classifier__n_estimators': [50, 100, 200],\n",
    "#         'classifier__max_depth': [None, 5, 10],\n",
    "#         'classifier__min_samples_split': [2, 5],\n",
    "#         'classifier__min_samples_leaf': [1, 2]\n",
    "#     },\n",
    "\n",
    "#     'Gradient Boosting': {\n",
    "#         'classifier__n_estimators': [50, 100, 200],\n",
    "#         'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "#         'classifier__max_depth': [3, 5, 7],\n",
    "#         'classifier__subsample': [0.8, 1.0]\n",
    "#     },\n",
    "\n",
    "#     'XGBoost': {\n",
    "#         'classifier__n_estimators': [50, 100],\n",
    "#         'classifier__max_depth': [3, 5],\n",
    "#         'classifier__learning_rate': [0.01, 0.1]\n",
    "#     },\n",
    "\n",
    "#     'CatBoost': {\n",
    "#         'classifier__iterations': [100, 200],\n",
    "#         'classifier__depth': [3, 5],\n",
    "#         'classifier__learning_rate': [0.01, 0.1]\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "743d60d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Second Params Grid (complex)\n",
    "# param_grids = {\n",
    "#     'Logistic Regression': [\n",
    "#         # liblinear supports l1, l2\n",
    "#         {\n",
    "#             'classifier__solver': ['liblinear'],\n",
    "#             'classifier__penalty': ['l1', 'l2'],\n",
    "#             'classifier__C': [0.01, 0.1, 1],\n",
    "#             'classifier__class_weight': [None, 'balanced']\n",
    "#         },\n",
    "#         # lbfgs supports only l2\n",
    "#         {\n",
    "#             'classifier__solver': ['lbfgs'],\n",
    "#             'classifier__penalty': ['l2'],\n",
    "#             'classifier__C': [0.01, 0.1, 1],\n",
    "#             'classifier__class_weight': [None, 'balanced']\n",
    "#         },\n",
    "#         # saga supports l1, l2, elasticnet\n",
    "#         {\n",
    "#             'classifier__solver': ['saga'],\n",
    "#             'classifier__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "#             'classifier__C': [0.01, 0.1, 1],\n",
    "#             'classifier__l1_ratio': [0.5],  # only used with elasticnet\n",
    "#             'classifier__class_weight': [None, 'balanced']\n",
    "#         }\n",
    "#     ],\n",
    "\n",
    "#     'Random Forest': {\n",
    "#         'classifier__n_estimators': [100, 300],\n",
    "#         'classifier__max_depth': [None, 10],\n",
    "#         'classifier__min_samples_split': [2, 5],\n",
    "#         'classifier__min_samples_leaf': [1, 2],\n",
    "#         'classifier__max_features': ['sqrt', 'log2'],\n",
    "#         'classifier__bootstrap': [True],\n",
    "#         'classifier__class_weight': [None, 'balanced']\n",
    "#     },\n",
    "\n",
    "#     'Gradient Boosting': {\n",
    "#         'classifier__n_estimators': [100, 300],\n",
    "#         'classifier__learning_rate': [0.05, 0.1],\n",
    "#         'classifier__max_depth': [3, 5],\n",
    "#         'classifier__min_samples_split': [2, 5],\n",
    "#         'classifier__min_samples_leaf': [1, 2],\n",
    "#         'classifier__subsample': [0.8, 1.0],\n",
    "#         'classifier__max_features': ['sqrt', None],\n",
    "#         'classifier__loss': ['log_loss']  # keep only main loss for binary classification\n",
    "#     },\n",
    "\n",
    "#     'XGBoost': {\n",
    "#         'classifier__n_estimators': [100, 300],\n",
    "#         'classifier__max_depth': [3, 5],\n",
    "#         'classifier__learning_rate': [0.05, 0.1],\n",
    "#         'classifier__subsample': [0.8, 1.0],\n",
    "#         'classifier__colsample_bytree': [0.8, 1.0],\n",
    "#         'classifier__gamma': [0, 0.1],\n",
    "#         'classifier__reg_alpha': [0, 0.1],\n",
    "#         'classifier__reg_lambda': [1, 1.5],\n",
    "#         'classifier__scale_pos_weight': [1]\n",
    "#     },\n",
    "\n",
    "#     'CatBoost': {\n",
    "#         'classifier__iterations': [200, 500],\n",
    "#         'classifier__depth': [6, 8],\n",
    "#         'classifier__learning_rate': [0.05, 0.1],\n",
    "#         'classifier__l2_leaf_reg': [3, 5],\n",
    "#         'classifier__border_count': [32, 64],\n",
    "#         'classifier__bagging_temperature': [0, 0.5],\n",
    "#         'classifier__random_strength': [0, 0.5],\n",
    "#         'classifier__boosting_type': ['Ordered']\n",
    "#     }\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6b3b1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third params grid (used grid, more evolved than the 1st)\n",
    "\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'classifier__C': [0.1, 1.0, 10.0],  # 3 values\n",
    "        'classifier__penalty': ['l2'],\n",
    "        'classifier__solver': ['lbfgs']  # Removed liblinear (lbfgs is faster)\n",
    "    },  # Total: 3 combinations\n",
    "\n",
    "    'Random Forest': {\n",
    "        'classifier__n_estimators': [100, 200],  # 2 values\n",
    "        'classifier__max_depth': [10, 20],  # 2 values (removed None - too slow)\n",
    "        'classifier__min_samples_split': [5, 10],  # 2 values\n",
    "        'classifier__class_weight': ['balanced']  # Fixed\n",
    "    },  # Total: 8 combinations\n",
    "\n",
    "    'Gradient Boosting': {\n",
    "        'classifier__n_estimators': [50, 100],  # 2 values\n",
    "        'classifier__learning_rate': [0.05, 0.1],  # 2 values\n",
    "        'classifier__max_depth': [3, 5],  # 2 values\n",
    "        'classifier__subsample': [0.8]  # Fixed\n",
    "    },  # Total: 8 combinations\n",
    "\n",
    "    'XGBoost': {\n",
    "        'classifier__n_estimators': [50, 100],  # 2 values\n",
    "        'classifier__max_depth': [3, 5],  # 2 values\n",
    "        'classifier__learning_rate': [0.05, 0.1],  # 2 values\n",
    "        'classifier__scale_pos_weight': [1]  # Fixed (or use balanced ratio)\n",
    "    },  # Total: 8 combinations\n",
    "\n",
    "    'CatBoost': {\n",
    "        'classifier__iterations': [100, 200],  # 2 values\n",
    "        'classifier__depth': [4, 6],  # 2 values\n",
    "        'classifier__learning_rate': [0.05, 0.1],  # 2 values\n",
    "        'classifier__auto_class_weights': ['Balanced']  # Fixed\n",
    "    }  # Total: 8 combinations\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a7b2c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to use during training\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(class_weight=\"balanced\", random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    'CatBoost': CatBoostClassifier(verbose=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571bcd43",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1fa3958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3971 993\n"
     ]
    }
   ],
   "source": [
    "split_idx = 36224 # 39130 or 36224\n",
    "\n",
    "bank_stable = bank_full.iloc[split_idx:].reset_index(drop=True)\n",
    "\n",
    "# chronological train/test split\n",
    "train_size = 0.8\n",
    "split = int(len(bank_stable)*train_size)\n",
    "train_set = bank_stable.iloc[:split].copy()\n",
    "test_set = bank_stable.iloc[split:].copy()\n",
    "\n",
    "# Split X and y from train dataset\n",
    "X_train = train_set.drop(columns=['y'])\n",
    "\n",
    "# Map target\n",
    "y_train = train_set.y\n",
    "\n",
    "print(len(X_train), len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341016ee",
   "metadata": {},
   "source": [
    "# Data preprocessing, feature engineering and training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47e34f0",
   "metadata": {},
   "source": [
    "keep cons.price.idx, remove emp.var.rate\n",
    "\n",
    "keep eurobr3m, remove nr.employed\n",
    "\n",
    "keep cons.price.idx, remove cons.conf.idx since its still higly correlated with emp.var.rate and euribor3m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53601aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ALBERTSCHOOL\\SupervisedML\\supervised_ml_project_waerniers_lamy\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [nan nan nan]\n",
      "  warnings.warn(\n",
      "Evaluating models:  20%|██        | 1/5 [00:09<00:36,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: Logistic Regression\n",
      "Grid Search: True\n",
      "Accuracy : 0.6472 ± 0.0402\n",
      "Precision: 0.6025 ± 0.0679\n",
      "Recall   : 0.5209 ± 0.2435\n",
      "F1       : 0.5313 ± 0.1511\n",
      "Time     : 9.07s\n",
      "Pipeline saved at: saved_pipelines\\Logistic_Regression_pipeline_1763571117.pkl\n",
      "\n",
      "######################################################################\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ALBERTSCHOOL\\SupervisedML\\supervised_ml_project_waerniers_lamy\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "Evaluating models:  40%|████      | 2/5 [00:15<00:23,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: Random Forest\n",
      "Grid Search: True\n",
      "Accuracy : 0.7785 ± 0.0330\n",
      "Precision: 0.7848 ± 0.0242\n",
      "Recall   : 0.6513 ± 0.2450\n",
      "F1       : 0.6845 ± 0.1510\n",
      "Time     : 6.55s\n",
      "Pipeline saved at: saved_pipelines\\Random_Forest_pipeline_1763571123.pkl\n",
      "\n",
      "######################################################################\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ALBERTSCHOOL\\SupervisedML\\supervised_ml_project_waerniers_lamy\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "Evaluating models:  60%|██████    | 3/5 [00:22<00:14,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: Gradient Boosting\n",
      "Grid Search: True\n",
      "Accuracy : 0.6805 ± 0.0244\n",
      "Precision: 0.7065 ± 0.0452\n",
      "Recall   : 0.4378 ± 0.1723\n",
      "F1       : 0.5219 ± 0.1386\n",
      "Time     : 6.61s\n",
      "Pipeline saved at: saved_pipelines\\Gradient_Boosting_pipeline_1763571130.pkl\n",
      "\n",
      "######################################################################\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ALBERTSCHOOL\\SupervisedML\\supervised_ml_project_waerniers_lamy\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "Evaluating models:  80%|████████  | 4/5 [00:25<00:05,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: XGBoost\n",
      "Grid Search: True\n",
      "Accuracy : 0.6735 ± 0.0269\n",
      "Precision: 0.6908 ± 0.0469\n",
      "Recall   : 0.4258 ± 0.1687\n",
      "F1       : 0.5102 ± 0.1396\n",
      "Time     : 2.63s\n",
      "Pipeline saved at: saved_pipelines\\XGBoost_pipeline_1763571133.pkl\n",
      "\n",
      "######################################################################\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ALBERTSCHOOL\\SupervisedML\\supervised_ml_project_waerniers_lamy\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "Evaluating models: 100%|██████████| 5/5 [00:34<00:00,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: CatBoost\n",
      "Grid Search: True\n",
      "Accuracy : 0.6838 ± 0.0262\n",
      "Precision: 0.6405 ± 0.0873\n",
      "Recall   : 0.5579 ± 0.2575\n",
      "F1       : 0.5697 ± 0.1675\n",
      "Time     : 9.49s\n",
      "Pipeline saved at: saved_pipelines\\CatBoost_pipeline_1763571142.pkl\n",
      "\n",
      "######################################################################\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Folds</th>\n",
       "      <th>Grid_search</th>\n",
       "      <th>Precision_mean</th>\n",
       "      <th>Precision_std</th>\n",
       "      <th>Recall_mean</th>\n",
       "      <th>Recall_std</th>\n",
       "      <th>F1_mean</th>\n",
       "      <th>F1_std</th>\n",
       "      <th>Accuracy_mean</th>\n",
       "      <th>Accuracy_std</th>\n",
       "      <th>Time</th>\n",
       "      <th>Pipeline_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.602490</td>\n",
       "      <td>0.067874</td>\n",
       "      <td>0.520865</td>\n",
       "      <td>0.243487</td>\n",
       "      <td>0.531343</td>\n",
       "      <td>0.151065</td>\n",
       "      <td>0.647201</td>\n",
       "      <td>0.040225</td>\n",
       "      <td>9.069630</td>\n",
       "      <td>saved_pipelines\\Logistic_Regression_pipeline_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.784766</td>\n",
       "      <td>0.024238</td>\n",
       "      <td>0.651311</td>\n",
       "      <td>0.244987</td>\n",
       "      <td>0.684457</td>\n",
       "      <td>0.151024</td>\n",
       "      <td>0.778517</td>\n",
       "      <td>0.032987</td>\n",
       "      <td>6.549681</td>\n",
       "      <td>saved_pipelines\\Random_Forest_pipeline_1763571...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.706529</td>\n",
       "      <td>0.045169</td>\n",
       "      <td>0.437772</td>\n",
       "      <td>0.172253</td>\n",
       "      <td>0.521881</td>\n",
       "      <td>0.138575</td>\n",
       "      <td>0.680484</td>\n",
       "      <td>0.024364</td>\n",
       "      <td>6.609526</td>\n",
       "      <td>saved_pipelines\\Gradient_Boosting_pipeline_176...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.690831</td>\n",
       "      <td>0.046939</td>\n",
       "      <td>0.425819</td>\n",
       "      <td>0.168727</td>\n",
       "      <td>0.510183</td>\n",
       "      <td>0.139618</td>\n",
       "      <td>0.673525</td>\n",
       "      <td>0.026883</td>\n",
       "      <td>2.631409</td>\n",
       "      <td>saved_pipelines\\XGBoost_pipeline_1763571133.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.640461</td>\n",
       "      <td>0.087331</td>\n",
       "      <td>0.557884</td>\n",
       "      <td>0.257492</td>\n",
       "      <td>0.569707</td>\n",
       "      <td>0.167537</td>\n",
       "      <td>0.683812</td>\n",
       "      <td>0.026203</td>\n",
       "      <td>9.491301</td>\n",
       "      <td>saved_pipelines\\CatBoost_pipeline_1763571142.pkl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Folds  Grid_search  Precision_mean  Precision_std  \\\n",
       "81  Logistic Regression      5         True        0.602490       0.067874   \n",
       "82        Random Forest      5         True        0.784766       0.024238   \n",
       "83    Gradient Boosting      5         True        0.706529       0.045169   \n",
       "84              XGBoost      5         True        0.690831       0.046939   \n",
       "85             CatBoost      5         True        0.640461       0.087331   \n",
       "\n",
       "    Recall_mean  Recall_std   F1_mean    F1_std  Accuracy_mean  Accuracy_std  \\\n",
       "81     0.520865    0.243487  0.531343  0.151065       0.647201      0.040225   \n",
       "82     0.651311    0.244987  0.684457  0.151024       0.778517      0.032987   \n",
       "83     0.437772    0.172253  0.521881  0.138575       0.680484      0.024364   \n",
       "84     0.425819    0.168727  0.510183  0.139618       0.673525      0.026883   \n",
       "85     0.557884    0.257492  0.569707  0.167537       0.683812      0.026203   \n",
       "\n",
       "        Time                                      Pipeline_file  \n",
       "81  9.069630  saved_pipelines\\Logistic_Regression_pipeline_1...  \n",
       "82  6.549681  saved_pipelines\\Random_Forest_pipeline_1763571...  \n",
       "83  6.609526  saved_pipelines\\Gradient_Boosting_pipeline_176...  \n",
       "84  2.631409    saved_pipelines\\XGBoost_pipeline_1763571133.pkl  \n",
       "85  9.491301   saved_pipelines\\CatBoost_pipeline_1763571142.pkl  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns to drop\n",
    "drop_cols = [\"duration\"]\n",
    "\n",
    "# Columns on which we will apply Standard Scaler\n",
    "std_cols = ['euribor3m', 'cons.price.idx', 'emp.var.rate', 'cons.conf.idx', 'nr.employed']\n",
    "\n",
    "# Columns on which we will apply Min Max Scaler\n",
    "minmax_cols = [\"age\", \"campaign\", \"pdays\", \"previous\"]\n",
    "\n",
    "# Columns on which we will apply One-Hot Encoder\n",
    "onehot_cols = ['job', 'marital', 'default', 'housing', 'loan', 'poutcome', \"contact\", \"month\"]\n",
    "\n",
    "# Columns on which we will apply Ordinal Encoder...\n",
    "ordinal_cols = [\"education\", \"day_of_week\"]\n",
    "# ... and their respective orders\n",
    "ordinal_categories = [[\"unknown\", \"illiterate\",\"basic.4y\",\"basic.6y\",\"basic.9y\",\"high.school\",\"professional.course\",\"university.degree\"],\n",
    "                      [\"mon\", \"tue\", \"wed\", \"thu\", \"fri\"]\n",
    "                      ]\n",
    "\n",
    "# Feature engineering functions\n",
    "ft_eng_pdays = FunctionTransformer(modify_pdays, validate=False)\n",
    "\n",
    "# Column transformers for preprocessing\n",
    "preprocessor = ColumnTransformer(transformers=[('drop_cols', 'drop', drop_cols),\n",
    "                                               ('std_scale', StandardScaler(), std_cols),\n",
    "                                               ('minmax_scale', MinMaxScaler(), minmax_cols),\n",
    "                                               ('one_hot', OneHotEncoder(), onehot_cols),\n",
    "                                               ('ordinal', OrdinalEncoder(categories = ordinal_categories), ordinal_cols)\n",
    "                                               ])\n",
    "\n",
    "\n",
    "# Training for each selected model\n",
    "for model_name, model in tqdm(models.items(), desc=\"Evaluating models\"):\n",
    "\n",
    "    pipeline = ImbPipeline(steps=[('feature_eng', ft_eng_pdays),\n",
    "                                  ('preprocessor', preprocessor),\n",
    "                                  ('classifier', model)])\n",
    "\n",
    "    train_ts(X_train=X_train,               # training set features\n",
    "                 y_train=y_train,           # training set target\n",
    "                 pipeline=pipeline,         # pipeline to use\n",
    "                 n_folds=5,                 # number of folds\n",
    "                 model_name = model_name,   # current model name\n",
    "                 param_grids=param_grids,   # put {} to avoid K fold and process a classic train/val training\n",
    "                 scoring_metrics=metrics,\n",
    "                 refit_metric='f1',     # optimizing metric, choose from 'recall', 'precision', 'f1', 'accuracy', etc...\n",
    "                 logs=pd.read_csv(os.path.join(cwd, 'data', 'train_logs.csv')))\n",
    "\n",
    "pd.read_csv(os.path.join(cwd, 'data', 'train_logs.csv')).tail(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
