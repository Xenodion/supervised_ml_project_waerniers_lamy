{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "969f3658",
   "metadata": {},
   "source": [
    "# Machine Learning Project\n",
    "by Alexandre Waerniers and Vincent Lamy,\n",
    "\n",
    "students at Albert School x Mines Paris PSL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac80c08f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d499db21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\ALBERTSCHOOL\\SupervisedML\\supervised_ml_project_waerniers_lamy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "\n",
    "from utils import bool_contact, train_ts\n",
    "\n",
    "# Get project path\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71fc32a",
   "metadata": {},
   "source": [
    "# Download datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c18be99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp.var.rate    41188 non-null  float64\n",
      " 16  cons.price.idx  41188 non-null  float64\n",
      " 17  cons.conf.idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr.employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  int64  \n",
      "dtypes: float64(5), int64(6), object(10)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# raw dataset\n",
    "bank_full = pd.read_csv(os.path.join(cwd, \"data\", \"bank-additional-full.csv\"), sep=\";\")\n",
    "bank_full.y = bank_full.y.map({\"yes\": 1, \"no\":0})\n",
    "\n",
    "bank_full.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b6ba13",
   "metadata": {},
   "source": [
    "# Define metrics, parameters and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c218bca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['precision', 'recall', 'f1', 'accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6637b771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First param grid (basic)\n",
    "# param_grids = {\n",
    "#     'Logistic Regression': {\n",
    "#         'classifier__C': [0.1, 1, 10, 100],\n",
    "#         'classifier__penalty': ['l2'],\n",
    "#         'classifier__solver': ['lbfgs', 'liblinear']\n",
    "#     },\n",
    "\n",
    "#     'Random Forest': {\n",
    "#         'classifier__n_estimators': [50, 100, 200],\n",
    "#         'classifier__max_depth': [None, 5, 10],\n",
    "#         'classifier__min_samples_split': [2, 5],\n",
    "#         'classifier__min_samples_leaf': [1, 2]\n",
    "#     },\n",
    "\n",
    "#     'Gradient Boosting': {\n",
    "#         'classifier__n_estimators': [50, 100, 200],\n",
    "#         'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "#         'classifier__max_depth': [3, 5, 7],\n",
    "#         'classifier__subsample': [0.8, 1.0]\n",
    "#     },\n",
    "\n",
    "#     'XGBoost': {\n",
    "#         'classifier__n_estimators': [50, 100],\n",
    "#         'classifier__max_depth': [3, 5],\n",
    "#         'classifier__learning_rate': [0.01, 0.1]\n",
    "#     },\n",
    "\n",
    "#     'CatBoost': {\n",
    "#         'classifier__iterations': [100, 200],\n",
    "#         'classifier__depth': [3, 5],\n",
    "#         'classifier__learning_rate': [0.01, 0.1]\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "743d60d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Second Params Grid (complex)\n",
    "# param_grids = {\n",
    "#     'Logistic Regression': [\n",
    "#         # liblinear supports l1, l2\n",
    "#         {\n",
    "#             'classifier__solver': ['liblinear'],\n",
    "#             'classifier__penalty': ['l1', 'l2'],\n",
    "#             'classifier__C': [0.01, 0.1, 1],\n",
    "#             'classifier__class_weight': [None, 'balanced']\n",
    "#         },\n",
    "#         # lbfgs supports only l2\n",
    "#         {\n",
    "#             'classifier__solver': ['lbfgs'],\n",
    "#             'classifier__penalty': ['l2'],\n",
    "#             'classifier__C': [0.01, 0.1, 1],\n",
    "#             'classifier__class_weight': [None, 'balanced']\n",
    "#         },\n",
    "#         # saga supports l1, l2, elasticnet\n",
    "#         {\n",
    "#             'classifier__solver': ['saga'],\n",
    "#             'classifier__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "#             'classifier__C': [0.01, 0.1, 1],\n",
    "#             'classifier__l1_ratio': [0.5],  # only used with elasticnet\n",
    "#             'classifier__class_weight': [None, 'balanced']\n",
    "#         }\n",
    "#     ],\n",
    "\n",
    "#     'Random Forest': {\n",
    "#         'classifier__n_estimators': [100, 300],\n",
    "#         'classifier__max_depth': [None, 10],\n",
    "#         'classifier__min_samples_split': [2, 5],\n",
    "#         'classifier__min_samples_leaf': [1, 2],\n",
    "#         'classifier__max_features': ['sqrt', 'log2'],\n",
    "#         'classifier__bootstrap': [True],\n",
    "#         'classifier__class_weight': [None, 'balanced']\n",
    "#     },\n",
    "\n",
    "#     'Gradient Boosting': {\n",
    "#         'classifier__n_estimators': [100, 300],\n",
    "#         'classifier__learning_rate': [0.05, 0.1],\n",
    "#         'classifier__max_depth': [3, 5],\n",
    "#         'classifier__min_samples_split': [2, 5],\n",
    "#         'classifier__min_samples_leaf': [1, 2],\n",
    "#         'classifier__subsample': [0.8, 1.0],\n",
    "#         'classifier__max_features': ['sqrt', None],\n",
    "#         'classifier__loss': ['log_loss']  # keep only main loss for binary classification\n",
    "#     },\n",
    "\n",
    "#     'XGBoost': {\n",
    "#         'classifier__n_estimators': [100, 300],\n",
    "#         'classifier__max_depth': [3, 5],\n",
    "#         'classifier__learning_rate': [0.05, 0.1],\n",
    "#         'classifier__subsample': [0.8, 1.0],\n",
    "#         'classifier__colsample_bytree': [0.8, 1.0],\n",
    "#         'classifier__gamma': [0, 0.1],\n",
    "#         'classifier__reg_alpha': [0, 0.1],\n",
    "#         'classifier__reg_lambda': [1, 1.5],\n",
    "#         'classifier__scale_pos_weight': [1]\n",
    "#     },\n",
    "\n",
    "#     'CatBoost': {\n",
    "#         'classifier__iterations': [200, 500],\n",
    "#         'classifier__depth': [6, 8],\n",
    "#         'classifier__learning_rate': [0.05, 0.1],\n",
    "#         'classifier__l2_leaf_reg': [3, 5],\n",
    "#         'classifier__border_count': [32, 64],\n",
    "#         'classifier__bagging_temperature': [0, 0.5],\n",
    "#         'classifier__random_strength': [0, 0.5],\n",
    "#         'classifier__boosting_type': ['Ordered']\n",
    "#     }\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b3b1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third params grid (used grid, more evolved than the 1st)\n",
    "\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'classifier__C': [0.1, 1.0, 10.0],  # 3 values\n",
    "        'classifier__penalty': ['l2'],\n",
    "        'classifier__solver': ['lbfgs']  # Removed liblinear (lbfgs is faster)\n",
    "    },  # Total: 3 combinations\n",
    "\n",
    "    'Random Forest': {\n",
    "        'classifier__n_estimators': [100, 200],  # 2 values\n",
    "        'classifier__max_depth': [10, 20],  # 2 values (removed None - too slow)\n",
    "        'classifier__min_samples_split': [5, 10],  # 2 values\n",
    "        'classifier__class_weight': ['balanced']  # Fixed\n",
    "    },  # Total: 8 combinations\n",
    "\n",
    "    'Gradient Boosting': {\n",
    "        'classifier__n_estimators': [50, 100],  # 2 values\n",
    "        'classifier__learning_rate': [0.05, 0.1],  # 2 values\n",
    "        'classifier__max_depth': [3, 5],  # 2 values\n",
    "        'classifier__subsample': [0.8]  # Fixed\n",
    "    },  # Total: 8 combinations\n",
    "\n",
    "    'XGBoost': {\n",
    "        'classifier__n_estimators': [50, 100],  # 2 values\n",
    "        'classifier__max_depth': [3, 5],  # 2 values\n",
    "        'classifier__learning_rate': [0.05, 0.1],  # 2 values\n",
    "        'classifier__scale_pos_weight': [1]  # Fixed (or use balanced ratio)\n",
    "    },  # Total: 8 combinations\n",
    "\n",
    "    'CatBoost': {\n",
    "        'classifier__iterations': [100, 200],  # 2 values\n",
    "        'classifier__depth': [4, 6],  # 2 values\n",
    "        'classifier__learning_rate': [0.05, 0.1],  # 2 values\n",
    "        'classifier__auto_class_weights': ['Balanced']  # Fixed\n",
    "    }  # Total: 8 combinations\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a7b2c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to use during training\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(class_weight=\"balanced\", random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    'CatBoost': CatBoostClassifier(verbose=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571bcd43",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fa3958",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = 36224 # 39130 or 36224\n",
    "\n",
    "bank_stable = bank_full.iloc[split_idx:].reset_index(drop=True)\n",
    "\n",
    "# chronological train/test split\n",
    "train_size = 0.8\n",
    "split = int(len(bank_stable)*train_size)\n",
    "train_set = bank_stable.iloc[:split].copy()\n",
    "test_set = bank_stable.iloc[split:].copy()\n",
    "\n",
    "# Split X and y from train dataset\n",
    "X_train = train_set.drop(columns=['y'])\n",
    "\n",
    "# Map target\n",
    "y_train = train_set.y\n",
    "\n",
    "print(len(X_train), len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341016ee",
   "metadata": {},
   "source": [
    "# Data preprocessing, feature engineering and training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47e34f0",
   "metadata": {},
   "source": [
    "keep cons.price.idx, remove emp.var.rate\n",
    "\n",
    "keep eurobr3m, remove nr.employed\n",
    "\n",
    "keep cons.price.idx, remove cons.conf.idx since its still higly correlated with emp.var.rate and euribor3m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53601aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:   0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\alexa\\anaconda3\\envs\\env_ml\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [nan nan nan]\n",
      "  warnings.warn(\n",
      "Evaluating models:  20%|██        | 1/5 [00:04<00:18,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions per fold:\n",
      "\n",
      "Fold 0:\n",
      "  Class:     [0 1]\n",
      "  True:      [442 219]\n",
      "  Predicted: [555 106]\n",
      "  Accuracy:  0.6596\n",
      "  Precision: 0.4717\n",
      "  Recall:    0.2283\n",
      "  F1-score:  0.3077\n",
      "\n",
      "Fold 1:\n",
      "  Class:     [0 1]\n",
      "  True:      [415 246]\n",
      "  Predicted: [519 142]\n",
      "  Accuracy:  0.6974\n",
      "  Precision: 0.6620\n",
      "  Recall:    0.3821\n",
      "  F1-score:  0.4845\n",
      "\n",
      "Fold 2:\n",
      "  Class:     [0 1]\n",
      "  True:      [363 298]\n",
      "  Predicted: [451 210]\n",
      "  Accuracy:  0.6248\n",
      "  Precision: 0.6190\n",
      "  Recall:    0.4362\n",
      "  F1-score:  0.5118\n",
      "\n",
      "Fold 3:\n",
      "  Class:     [0 1]\n",
      "  True:      [313 348]\n",
      "  Predicted: [283 378]\n",
      "  Accuracy:  0.6127\n",
      "  Precision: 0.6217\n",
      "  Recall:    0.6753\n",
      "  F1-score:  0.6474\n",
      "\n",
      "Fold 4:\n",
      "  Class:     [0 1]\n",
      "  True:      [310 351]\n",
      "  Predicted: [176 485]\n",
      "  Accuracy:  0.6793\n",
      "  Precision: 0.6433\n",
      "  Recall:    0.8889\n",
      "  F1-score:  0.7464\n",
      "\n",
      "Model: Logistic Regression\n",
      "Grid Search: True\n",
      "Accuracy : 0.6548 ± 0.0320\n",
      "Precision: 0.6035 ± 0.0677\n",
      "Recall   : 0.5222 ± 0.2329\n",
      "F1       : 0.5396 ± 0.1496\n",
      "Time     : 4.72s\n",
      "Pipeline saved at: saved_pipelines\\Logistic_Regression_pipeline_1763225776.pkl\n",
      "\n",
      "######################################################################\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexa\\anaconda3\\envs\\env_ml\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions per fold:\n",
      "\n",
      "Fold 0:\n",
      "  Class:     [0 1]\n",
      "  True:      [442 219]\n",
      "  Predicted: [559 102]\n",
      "  Accuracy:  0.7110\n",
      "  Precision: 0.6373\n",
      "  Recall:    0.2968\n",
      "  F1-score:  0.4050\n",
      "\n",
      "Fold 1:\n",
      "  Class:     [0 1]\n",
      "  True:      [415 246]\n",
      "  Predicted: [529 132]\n",
      "  Accuracy:  0.7398\n",
      "  Precision: 0.7803\n",
      "  Recall:    0.4187\n",
      "  F1-score:  0.5450\n",
      "\n",
      "Fold 2:\n",
      "  Class:     [0 1]\n",
      "  True:      [363 298]\n",
      "  Predicted: [412 249]\n",
      "  Accuracy:  0.7776\n",
      "  Precision: 0.8032\n",
      "  Recall:    0.6711\n",
      "  F1-score:  0.7313\n",
      "\n",
      "Fold 3:\n",
      "  Class:     [0 1]\n",
      "  True:      [313 348]\n",
      "  Predicted: [258 403]\n",
      "  Accuracy:  0.8048\n",
      "  Precision: 0.7717\n",
      "  Recall:    0.8937\n",
      "  F1-score:  0.8282\n",
      "\n",
      "Fold 4:\n",
      "  Class:     [0 1]\n",
      "  True:      [310 351]\n",
      "  Predicted: [265 396]\n",
      "  Accuracy:  0.8411\n",
      "  Precision: 0.8106\n",
      "  Recall:    0.9145\n",
      "  F1-score:  0.8594\n",
      "\n",
      "Model: Random Forest\n",
      "Grid Search: True\n",
      "Accuracy : 0.7749 ± 0.0461\n",
      "Precision: 0.7606 ± 0.0633\n",
      "Recall   : 0.6390 ± 0.2480\n",
      "F1       : 0.6738 ± 0.1735\n",
      "Time     : 4.41s\n",
      "Pipeline saved at: saved_pipelines\\Random_Forest_pipeline_1763225781.pkl\n",
      "\n",
      "######################################################################\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models:  40%|████      | 2/5 [00:09<00:13,  4.57s/it]c:\\Users\\alexa\\anaconda3\\envs\\env_ml\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "Evaluating models:  60%|██████    | 3/5 [00:13<00:08,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions per fold:\n",
      "\n",
      "Fold 0:\n",
      "  Class:     [0 1]\n",
      "  True:      [442 219]\n",
      "  Predicted: [586  75]\n",
      "  Accuracy:  0.6823\n",
      "  Precision: 0.5600\n",
      "  Recall:    0.1918\n",
      "  F1-score:  0.2857\n",
      "\n",
      "Fold 1:\n",
      "  Class:     [0 1]\n",
      "  True:      [415 246]\n",
      "  Predicted: [545 116]\n",
      "  Accuracy:  0.7126\n",
      "  Precision: 0.7414\n",
      "  Recall:    0.3496\n",
      "  F1-score:  0.4751\n",
      "\n",
      "Fold 2:\n",
      "  Class:     [0 1]\n",
      "  True:      [363 298]\n",
      "  Predicted: [516 145]\n",
      "  Accuracy:  0.6505\n",
      "  Precision: 0.7310\n",
      "  Recall:    0.3557\n",
      "  F1-score:  0.4786\n",
      "\n",
      "Fold 3:\n",
      "  Class:     [0 1]\n",
      "  True:      [313 348]\n",
      "  Predicted: [357 304]\n",
      "  Accuracy:  0.6369\n",
      "  Precision: 0.6776\n",
      "  Recall:    0.5920\n",
      "  F1-score:  0.6319\n",
      "\n",
      "Fold 4:\n",
      "  Class:     [0 1]\n",
      "  True:      [310 351]\n",
      "  Predicted: [363 298]\n",
      "  Accuracy:  0.6929\n",
      "  Precision: 0.7483\n",
      "  Recall:    0.6353\n",
      "  F1-score:  0.6872\n",
      "\n",
      "Model: Gradient Boosting\n",
      "Grid Search: True\n",
      "Accuracy : 0.6750 ± 0.0277\n",
      "Precision: 0.6917 ± 0.0704\n",
      "Recall   : 0.4249 ± 0.1655\n",
      "F1       : 0.5117 ± 0.1405\n",
      "Time     : 4.04s\n",
      "Pipeline saved at: saved_pipelines\\Gradient_Boosting_pipeline_1763225785.pkl\n",
      "\n",
      "######################################################################\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexa\\anaconda3\\envs\\env_ml\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "Evaluating models:  80%|████████  | 4/5 [00:14<00:03,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions per fold:\n",
      "\n",
      "Fold 0:\n",
      "  Class:     [0 1]\n",
      "  True:      [442 219]\n",
      "  Predicted: [593  68]\n",
      "  Accuracy:  0.6899\n",
      "  Precision: 0.6029\n",
      "  Recall:    0.1872\n",
      "  F1-score:  0.2857\n",
      "\n",
      "Fold 1:\n",
      "  Class:     [0 1]\n",
      "  True:      [415 246]\n",
      "  Predicted: [542 119]\n",
      "  Accuracy:  0.7050\n",
      "  Precision: 0.7143\n",
      "  Recall:    0.3455\n",
      "  F1-score:  0.4658\n",
      "\n",
      "Fold 2:\n",
      "  Class:     [0 1]\n",
      "  True:      [363 298]\n",
      "  Predicted: [519 142]\n",
      "  Accuracy:  0.6490\n",
      "  Precision: 0.7324\n",
      "  Recall:    0.3490\n",
      "  F1-score:  0.4727\n",
      "\n",
      "Fold 3:\n",
      "  Class:     [0 1]\n",
      "  True:      [313 348]\n",
      "  Predicted: [359 302]\n",
      "  Accuracy:  0.6278\n",
      "  Precision: 0.6689\n",
      "  Recall:    0.5805\n",
      "  F1-score:  0.6215\n",
      "\n",
      "Fold 4:\n",
      "  Class:     [0 1]\n",
      "  True:      [310 351]\n",
      "  Predicted: [363 298]\n",
      "  Accuracy:  0.6868\n",
      "  Precision: 0.7416\n",
      "  Recall:    0.6296\n",
      "  F1-score:  0.6810\n",
      "\n",
      "Model: XGBoost\n",
      "Grid Search: True\n",
      "Accuracy : 0.6717 ± 0.0287\n",
      "Precision: 0.6920 ± 0.0511\n",
      "Recall   : 0.4184 ± 0.1640\n",
      "F1       : 0.5054 ± 0.1380\n",
      "Time     : 1.47s\n",
      "Pipeline saved at: saved_pipelines\\XGBoost_pipeline_1763225786.pkl\n",
      "\n",
      "######################################################################\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexa\\anaconda3\\envs\\env_ml\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "Evaluating models: 100%|██████████| 5/5 [00:22<00:00,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions per fold:\n",
      "\n",
      "Fold 0:\n",
      "  Class:     [0 1]\n",
      "  True:      [442 219]\n",
      "  Predicted: [562  99]\n",
      "  Accuracy:  0.6641\n",
      "  Precision: 0.4848\n",
      "  Recall:    0.2192\n",
      "  F1-score:  0.3019\n",
      "\n",
      "Fold 1:\n",
      "  Class:     [0 1]\n",
      "  True:      [415 246]\n",
      "  Predicted: [539 122]\n",
      "  Accuracy:  0.7065\n",
      "  Precision: 0.7131\n",
      "  Recall:    0.3537\n",
      "  F1-score:  0.4728\n",
      "\n",
      "Fold 2:\n",
      "  Class:     [0 1]\n",
      "  True:      [363 298]\n",
      "  Predicted: [432 229]\n",
      "  Accuracy:  0.6838\n",
      "  Precision: 0.6943\n",
      "  Recall:    0.5336\n",
      "  F1-score:  0.6034\n",
      "\n",
      "Fold 3:\n",
      "  Class:     [0 1]\n",
      "  True:      [313 348]\n",
      "  Predicted: [234 427]\n",
      "  Accuracy:  0.6566\n",
      "  Precision: 0.6417\n",
      "  Recall:    0.7874\n",
      "  F1-score:  0.7071\n",
      "\n",
      "Fold 4:\n",
      "  Class:     [0 1]\n",
      "  True:      [310 351]\n",
      "  Predicted: [234 427]\n",
      "  Accuracy:  0.7126\n",
      "  Precision: 0.6885\n",
      "  Recall:    0.8376\n",
      "  F1-score:  0.7558\n",
      "\n",
      "Model: CatBoost\n",
      "Grid Search: True\n",
      "Accuracy : 0.6847 ± 0.0222\n",
      "Precision: 0.6445 ± 0.0832\n",
      "Recall   : 0.5463 ± 0.2397\n",
      "F1       : 0.5682 ± 0.1648\n",
      "Time     : 7.52s\n",
      "Pipeline saved at: saved_pipelines\\CatBoost_pipeline_1763225794.pkl\n",
      "\n",
      "######################################################################\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Folds</th>\n",
       "      <th>Grid_search</th>\n",
       "      <th>Precision_mean</th>\n",
       "      <th>Precision_std</th>\n",
       "      <th>Recall_mean</th>\n",
       "      <th>Recall_std</th>\n",
       "      <th>F1_mean</th>\n",
       "      <th>F1_std</th>\n",
       "      <th>Accuracy_mean</th>\n",
       "      <th>Accuracy_std</th>\n",
       "      <th>Time</th>\n",
       "      <th>Pipeline_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.611653</td>\n",
       "      <td>0.100242</td>\n",
       "      <td>0.444134</td>\n",
       "      <td>0.077803</td>\n",
       "      <td>0.514380</td>\n",
       "      <td>0.086959</td>\n",
       "      <td>0.640242</td>\n",
       "      <td>0.033012</td>\n",
       "      <td>0.341241</td>\n",
       "      <td>saved_pipelines\\Logistic_Regression_pipeline_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.752626</td>\n",
       "      <td>0.066298</td>\n",
       "      <td>0.560174</td>\n",
       "      <td>0.067880</td>\n",
       "      <td>0.641552</td>\n",
       "      <td>0.065023</td>\n",
       "      <td>0.731619</td>\n",
       "      <td>0.028167</td>\n",
       "      <td>8.423356</td>\n",
       "      <td>saved_pipelines\\Random_Forest_pipeline_1763224...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.689554</td>\n",
       "      <td>0.099339</td>\n",
       "      <td>0.371141</td>\n",
       "      <td>0.089359</td>\n",
       "      <td>0.480878</td>\n",
       "      <td>0.097130</td>\n",
       "      <td>0.658699</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>4.180241</td>\n",
       "      <td>saved_pipelines\\Gradient_Boosting_pipeline_176...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.685032</td>\n",
       "      <td>0.099502</td>\n",
       "      <td>0.368514</td>\n",
       "      <td>0.088932</td>\n",
       "      <td>0.477623</td>\n",
       "      <td>0.097187</td>\n",
       "      <td>0.656581</td>\n",
       "      <td>0.034379</td>\n",
       "      <td>1.214185</td>\n",
       "      <td>saved_pipelines\\XGBoost_pipeline_1763224479.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.668652</td>\n",
       "      <td>0.102048</td>\n",
       "      <td>0.396695</td>\n",
       "      <td>0.087622</td>\n",
       "      <td>0.497114</td>\n",
       "      <td>0.095960</td>\n",
       "      <td>0.657489</td>\n",
       "      <td>0.033918</td>\n",
       "      <td>6.344752</td>\n",
       "      <td>saved_pipelines\\CatBoost_pipeline_1763224485.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.603542</td>\n",
       "      <td>0.067746</td>\n",
       "      <td>0.522168</td>\n",
       "      <td>0.232929</td>\n",
       "      <td>0.539567</td>\n",
       "      <td>0.149649</td>\n",
       "      <td>0.654766</td>\n",
       "      <td>0.031970</td>\n",
       "      <td>4.721630</td>\n",
       "      <td>saved_pipelines\\Logistic_Regression_pipeline_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.760618</td>\n",
       "      <td>0.063312</td>\n",
       "      <td>0.638970</td>\n",
       "      <td>0.247968</td>\n",
       "      <td>0.673777</td>\n",
       "      <td>0.173476</td>\n",
       "      <td>0.774887</td>\n",
       "      <td>0.046051</td>\n",
       "      <td>4.405922</td>\n",
       "      <td>saved_pipelines\\Random_Forest_pipeline_1763225...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.691674</td>\n",
       "      <td>0.070376</td>\n",
       "      <td>0.424872</td>\n",
       "      <td>0.165524</td>\n",
       "      <td>0.511704</td>\n",
       "      <td>0.140540</td>\n",
       "      <td>0.675038</td>\n",
       "      <td>0.027688</td>\n",
       "      <td>4.040267</td>\n",
       "      <td>saved_pipelines\\Gradient_Boosting_pipeline_176...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.692021</td>\n",
       "      <td>0.051100</td>\n",
       "      <td>0.418365</td>\n",
       "      <td>0.163985</td>\n",
       "      <td>0.505356</td>\n",
       "      <td>0.138016</td>\n",
       "      <td>0.671710</td>\n",
       "      <td>0.028657</td>\n",
       "      <td>1.465540</td>\n",
       "      <td>saved_pipelines\\XGBoost_pipeline_1763225786.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.644499</td>\n",
       "      <td>0.083217</td>\n",
       "      <td>0.546271</td>\n",
       "      <td>0.239687</td>\n",
       "      <td>0.568202</td>\n",
       "      <td>0.164766</td>\n",
       "      <td>0.684720</td>\n",
       "      <td>0.022206</td>\n",
       "      <td>7.522618</td>\n",
       "      <td>saved_pipelines\\CatBoost_pipeline_1763225794.pkl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Folds  Grid_search  Precision_mean  Precision_std  \\\n",
       "45  Logistic Regression      5         True        0.611653       0.100242   \n",
       "46        Random Forest      5         True        0.752626       0.066298   \n",
       "47    Gradient Boosting      5         True        0.689554       0.099339   \n",
       "48              XGBoost      5         True        0.685032       0.099502   \n",
       "49             CatBoost      5         True        0.668652       0.102048   \n",
       "50  Logistic Regression      5         True        0.603542       0.067746   \n",
       "51        Random Forest      5         True        0.760618       0.063312   \n",
       "52    Gradient Boosting      5         True        0.691674       0.070376   \n",
       "53              XGBoost      5         True        0.692021       0.051100   \n",
       "54             CatBoost      5         True        0.644499       0.083217   \n",
       "\n",
       "    Recall_mean  Recall_std   F1_mean    F1_std  Accuracy_mean  Accuracy_std  \\\n",
       "45     0.444134    0.077803  0.514380  0.086959       0.640242      0.033012   \n",
       "46     0.560174    0.067880  0.641552  0.065023       0.731619      0.028167   \n",
       "47     0.371141    0.089359  0.480878  0.097130       0.658699      0.034400   \n",
       "48     0.368514    0.088932  0.477623  0.097187       0.656581      0.034379   \n",
       "49     0.396695    0.087622  0.497114  0.095960       0.657489      0.033918   \n",
       "50     0.522168    0.232929  0.539567  0.149649       0.654766      0.031970   \n",
       "51     0.638970    0.247968  0.673777  0.173476       0.774887      0.046051   \n",
       "52     0.424872    0.165524  0.511704  0.140540       0.675038      0.027688   \n",
       "53     0.418365    0.163985  0.505356  0.138016       0.671710      0.028657   \n",
       "54     0.546271    0.239687  0.568202  0.164766       0.684720      0.022206   \n",
       "\n",
       "        Time                                      Pipeline_file  \n",
       "45  0.341241  saved_pipelines\\Logistic_Regression_pipeline_1...  \n",
       "46  8.423356  saved_pipelines\\Random_Forest_pipeline_1763224...  \n",
       "47  4.180241  saved_pipelines\\Gradient_Boosting_pipeline_176...  \n",
       "48  1.214185    saved_pipelines\\XGBoost_pipeline_1763224479.pkl  \n",
       "49  6.344752   saved_pipelines\\CatBoost_pipeline_1763224485.pkl  \n",
       "50  4.721630  saved_pipelines\\Logistic_Regression_pipeline_1...  \n",
       "51  4.405922  saved_pipelines\\Random_Forest_pipeline_1763225...  \n",
       "52  4.040267  saved_pipelines\\Gradient_Boosting_pipeline_176...  \n",
       "53  1.465540    saved_pipelines\\XGBoost_pipeline_1763225786.pkl  \n",
       "54  7.522618   saved_pipelines\\CatBoost_pipeline_1763225794.pkl  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns to drop\n",
    "drop_cols = [\"duration\", \"month\", 'emp.var.rate', 'cons.conf.idx', 'nr.employed']\n",
    "\n",
    "# Columns on which we will apply Standard Scaler\n",
    "std_cols = [\"age\", \"campaign\", \"pdays\", \"previous\", 'euribor3m', 'cons.price.idx',]\n",
    "\n",
    "# Columns on which we will apply Min Max Scaler\n",
    "minmax_cols = [\"campaign\"]\n",
    "\n",
    "# Columns on which we will apply One-Hot Encoder\n",
    "onehot_cols = ['job', 'marital', 'default', 'housing', 'loan', 'poutcome', \"contact\", \"education\", \"day_of_week\"]\n",
    "\n",
    "# Columns on which we will apply Ordinal Encoder...\n",
    "ordinal_cols = [\"education\", \"day_of_week\"]\n",
    "# ... and their respective orders\n",
    "ordinal_categories = [[\"unknown\", \"illiterate\",\"basic.4y\",\"basic.6y\",\"basic.9y\",\"high.school\",\"professional.course\",\"university.degree\"],\n",
    "                      [\"mon\", \"tue\", \"wed\", \"thu\", \"fri\"]\n",
    "                      ]\n",
    "\n",
    "# Column on which we will apply feature engineering\n",
    "bool_cols = [\"contact\"]\n",
    "\n",
    "# Feature engineering functions\n",
    "ft_eng_contact = FunctionTransformer(bool_contact, validate=False)\n",
    "\n",
    "# Column transformers for preprocessing\n",
    "preprocessor = ColumnTransformer(transformers=[('drop_cols', 'drop', drop_cols),\n",
    "                                               ('std_scale', StandardScaler(), std_cols),\n",
    "                                               # ('minmax_scale', MinMaxScaler(), minmax_cols),\n",
    "                                               ('one_hot', OneHotEncoder(), onehot_cols),\n",
    "                                               # ('ordinal', OrdinalEncoder(categories = ordinal_categories), ordinal_cols)\n",
    "                                               ])\n",
    "\n",
    "\n",
    "# Training for each selected model\n",
    "for model_name, model in tqdm(models.items(), desc=\"Evaluating models\"):\n",
    "\n",
    "    pipeline = ImbPipeline(steps=[# ('fetaure_eng', ft_eng_contact),\n",
    "                                  ('preprocessor', preprocessor),\n",
    "                                  ('classifier', model)])\n",
    "\n",
    "    train_ts(X_train=X_train,               # training set features\n",
    "                 y_train=y_train,           # training set target\n",
    "                 pipeline=pipeline,         # pipeline to use\n",
    "                 n_folds=5,                 # number of folds\n",
    "                 model_name = model_name,   # current model name\n",
    "                 param_grids=param_grids,   # put {} to avoid K fold and process a classic train/val training\n",
    "                 scoring_metrics=metrics,\n",
    "                 refit_metric='accuracy',     # optimizing metric, choose from 'recall', 'precision', 'f1', 'accuracy', etc...\n",
    "                 logs=pd.read_csv(os.path.join(cwd, 'data', 'train_logs.csv')))\n",
    "\n",
    "pd.read_csv(os.path.join(cwd, 'data', 'train_logs.csv')).tail(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
